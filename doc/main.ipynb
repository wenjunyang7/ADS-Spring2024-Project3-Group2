{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "aba40373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec20cb",
   "metadata": {},
   "source": [
    "## 1. Load the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd267f5",
   "metadata": {},
   "source": [
    "For the project, we provide a training set with 50000 images in the directory `../data/images/` with:\n",
    "- noisy labels for all images provided in `../data/noisy_label.csv`;\n",
    "- clean labels for the first 10000 images provided in `../data/clean_labels.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "76c791f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "\n",
    "# load the images\n",
    "n_img = 50000\n",
    "n_noisy = 40000\n",
    "n_clean_noisy = n_img - n_noisy\n",
    "imgs = np.empty((n_img,32,32,3))\n",
    "for i in range(n_img):\n",
    "    img_fn = f'../data/images/{i+1:05d}.png'\n",
    "    imgs[i,:,:,:]=cv2.cvtColor(cv2.imread(img_fn),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# load the labels\n",
    "clean_labels = np.genfromtxt('clean_labels.csv', delimiter=',', dtype=\"int8\")\n",
    "noisy_labels = np.genfromtxt('noisy_labels.csv', delimiter=',', dtype=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fbd8babc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 9, ..., 9, 1, 1], dtype=int8)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa69453",
   "metadata": {},
   "source": [
    "For illustration, we present a small subset (of size 8) of the images with their clean and noisy labels in `clean_noisy_trainset`. You are encouraged to explore more characteristics of the label noises on the whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e7259fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noisy_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "253c2151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean labels:\n",
      " frog truck truck  deer   car   car  bird horse\n",
      "Noisy labels:\n",
      "  cat   dog truck  frog   dog  ship  bird  deer\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(2,4,1)\n",
    "ax1.imshow(imgs[0]/255)\n",
    "ax2 = fig.add_subplot(2,4,2)\n",
    "ax2.imshow(imgs[1]/255)\n",
    "ax3 = fig.add_subplot(2,4,3)\n",
    "ax3.imshow(imgs[2]/255)\n",
    "ax4 = fig.add_subplot(2,4,4)\n",
    "ax4.imshow(imgs[3]/255)\n",
    "ax1 = fig.add_subplot(2,4,5)\n",
    "ax1.imshow(imgs[4]/255)\n",
    "ax2 = fig.add_subplot(2,4,6)\n",
    "ax2.imshow(imgs[5]/255)\n",
    "ax3 = fig.add_subplot(2,4,7)\n",
    "ax3.imshow(imgs[6]/255)\n",
    "ax4 = fig.add_subplot(2,4,8)\n",
    "ax4.imshow(imgs[7]/255)\n",
    "\n",
    "# The class-label correspondence\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# print clean labels\n",
    "print('Clean labels:')\n",
    "print(' '.join('%5s' % classes[clean_labels[j]] for j in range(8)))\n",
    "# print noisy labels\n",
    "print('Noisy labels:')\n",
    "print(' '.join('%5s' % classes[noisy_labels[j]] for j in range(8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b0c03",
   "metadata": {},
   "source": [
    "## 2. The predictive model\n",
    "\n",
    "We consider a baseline model directly on the noisy dataset without any label corrections. RGB histogram features are extracted to fit a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b2f66e",
   "metadata": {},
   "source": [
    "### 2.1. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e7b3f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "# RGB histogram dataset construction\n",
    "no_bins = 6\n",
    "bins = np.linspace(0,255,no_bins) # the range of the rgb histogram\n",
    "target_vec = np.empty(n_img)\n",
    "feature_mtx = np.empty((n_img,3*(len(bins)-1)))\n",
    "i = 0\n",
    "for i in range(n_img):\n",
    "    # The target vector consists of noisy labels\n",
    "    target_vec[i] = noisy_labels[i]\n",
    "    \n",
    "    # Use the numbers of pixels in each bin for all three channels as the features\n",
    "    feature1 = np.histogram(imgs[i][:,:,0],bins=bins)[0] \n",
    "    feature2 = np.histogram(imgs[i][:,:,1],bins=bins)[0]\n",
    "    feature3 = np.histogram(imgs[i][:,:,2],bins=bins)[0]\n",
    "    \n",
    "    # Concatenate three features\n",
    "    feature_mtx[i,] = np.concatenate((feature1, feature2, feature3), axis=None)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "395cc851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "# Train a logistic regression model \n",
    "clf = LogisticRegression(random_state=0).fit(feature_mtx, target_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e6a9dd",
   "metadata": {},
   "source": [
    "For the convenience of evaluation, we write the following function `predictive_model` that does the label prediction. **For your predictive model, feel free to modify the function, but make sure the function takes an RGB image of numpy.array format with dimension $32\\times32\\times3$  as input, and returns one single label as output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2157bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "def baseline_model(image):\n",
    "    '''\n",
    "    This is the baseline predictive model that takes in the image and returns a label prediction\n",
    "    '''\n",
    "    feature1 = np.histogram(image[:,:,0],bins=bins)[0]\n",
    "    feature2 = np.histogram(image[:,:,1],bins=bins)[0]\n",
    "    feature3 = np.histogram(image[:,:,2],bins=bins)[0]\n",
    "    feature = np.concatenate((feature1, feature2, feature3), axis=None).reshape(1,-1)\n",
    "    return clf.predict(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4af5e5d",
   "metadata": {},
   "source": [
    "### 2.2. Model I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbe631a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 65ms/step - accuracy: 0.1206 - loss: 2.7503 - val_accuracy: 0.1388 - val_loss: 3.0546\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 65ms/step - accuracy: 0.1519 - loss: 2.4058 - val_accuracy: 0.2125 - val_loss: 2.2662\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 65ms/step - accuracy: 0.1647 - loss: 2.3489 - val_accuracy: 0.3250 - val_loss: 1.9991\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 65ms/step - accuracy: 0.1652 - loss: 2.3106 - val_accuracy: 0.2945 - val_loss: 2.0657\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 65ms/step - accuracy: 0.1689 - loss: 2.2906 - val_accuracy: 0.3878 - val_loss: 1.9370\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 65ms/step - accuracy: 0.1807 - loss: 2.2679 - val_accuracy: 0.3882 - val_loss: 1.9419\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 65ms/step - accuracy: 0.2014 - loss: 2.2463 - val_accuracy: 0.4310 - val_loss: 1.8101\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 65ms/step - accuracy: 0.2038 - loss: 2.2389 - val_accuracy: 0.3736 - val_loss: 1.9128\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 65ms/step - accuracy: 0.2110 - loss: 2.2282 - val_accuracy: 0.4324 - val_loss: 1.8958\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 65ms/step - accuracy: 0.2188 - loss: 2.2166 - val_accuracy: 0.4720 - val_loss: 1.8525\n",
      "Training accuracy:  0.21995000541210175\n",
      "Validation accuracy:  0.47200000286102295\n",
      "313/313 - 3s - 10ms/step - accuracy: 0.4720 - loss: 1.8525\n",
      "\n",
      "Test accuracy: 0.47200000286102295\n",
      "Runtime of the first part: 821.6063859462738 seconds\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def build_cnn_model(input_shape=(32, 32, 3), num_classes=10):\n",
    "    # initialize the model as a sequential model\n",
    "    model = models.Sequential([ \n",
    "        # add a convolutional layer with 64 filters, a 3x3 kernel, using 'same' padding, and ReLU activation. It's the first layer\n",
    "        layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "        # add batch normalization to normalize the activations of the previous layer\n",
    "        layers.BatchNormalization(),\n",
    "        # another convolutional layer with 64 filters and ReLU activation without padding specification, which defaults to 'valid'\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        # add max pooling to reduce spatial dimensions by taking the maximum value over a 2x2 pooling window\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        # add dropout to prevent overfitting by randomly setting a fraction of inputs to 0 during training\n",
    "        layers.Dropout(0.25),\n",
    "\n",
    "        # add another set of convolutional layers and batch normalization, similar to above but with 128 filters\n",
    "        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "\n",
    "        # flatten the output of the previous layer to a 1D array to be used as input for the dense layers\n",
    "        layers.Flatten(),\n",
    "        # add a densely connected layer with 1024 neurons and ReLU activation\n",
    "        layers.Dense(1024, activation='relu'),\n",
    "        # add another batch normalization step\n",
    "        layers.BatchNormalization(),\n",
    "        # add dropout to further prevent overfitting\n",
    "        layers.Dropout(0.5),\n",
    "        # add a final densely connected layer with a number of neurons equal to the number of classes, using softmax activation for multi-class classification\n",
    "        layers.Dense(num_classes, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    # compile the model with Adam optimizer, sparse categorical crossentropy as the loss function, and track accuracy as a metric\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "x_train = imgs[10000:] / 255 \n",
    "x_test = imgs[:10000] / 255 \n",
    "y_train = noisy_labels[10000:]  \n",
    "y_test = clean_labels\n",
    "\n",
    "model = build_cnn_model() \n",
    "\n",
    "# early stopping to halt training \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "# train the model\n",
    "history = model.fit(x_train, y_train, batch_size=32,\n",
    "                    epochs=10, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    callbacks=[early_stopping])  \n",
    "\n",
    "# extract training and validation accuracy from the training \n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "print(\"Training accuracy: \", train_acc[-1])  # print the last training accuracy\n",
    "print(\"Validation accuracy: \", val_acc[-1])  # print the last validation accuracy\n",
    "\n",
    "# evaluate the model on the test dataset to get the loss value & metrics values\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)  # print the test accuracy\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Runtime of the first part: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9f093978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save(\"model1.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c471532",
   "metadata": {},
   "source": [
    "### 2.3. Model II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65bedad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ADD WEAKLY SUPERVISED LEARNING FEATURE TO MODEL I]\n",
    "\n",
    "# write your code here...\n",
    "\n",
    "def model_II(image):\n",
    "    '''\n",
    "    This function should takes in the image of dimension 32*32*3 as input and returns a label prediction\n",
    "    '''\n",
    "    # write your code here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae8dcd34-8b1c-433f-9668-a3aca9fbc014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h5py==3.7.0\n",
      "  Downloading h5py-3.7.0-cp39-cp39-win_amd64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in d:\\anaconda\\lib\\site-packages (from h5py==3.7.0) (1.23.5)\n",
      "Downloading h5py-3.7.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.6 MB 1.3 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.2/2.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.5/2.6 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.0/2.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.1/2.6 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.2/2.6 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.6/2.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.9/2.6 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.4/2.6 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 5.6 MB/s eta 0:00:00\n",
      "Installing collected packages: h5py\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.10.0\n",
      "    Uninstalling h5py-3.10.0:\n",
      "      Successfully uninstalled h5py-3.10.0\n",
      "Successfully installed h5py-3.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (d:\\anaconda\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.16.1 requires h5py>=3.10.0, but you have h5py 3.7.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install h5py==3.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d75cbff",
   "metadata": {},
   "source": [
    "without kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdb5c4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.2916 - loss: 2.2072 - val_accuracy: 0.1625 - val_loss: 2.3881 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.4812 - loss: 1.4349 - val_accuracy: 0.3760 - val_loss: 1.6921 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5634 - loss: 1.2450 - val_accuracy: 0.3970 - val_loss: 1.6805 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6182 - loss: 1.0758 - val_accuracy: 0.4435 - val_loss: 1.5848 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6723 - loss: 0.9284 - val_accuracy: 0.5190 - val_loss: 1.4056 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6977 - loss: 0.8506 - val_accuracy: 0.4955 - val_loss: 1.4654 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7450 - loss: 0.7163 - val_accuracy: 0.5445 - val_loss: 1.4382 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7879 - loss: 0.6112 - val_accuracy: 0.5575 - val_loss: 1.4435 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8716 - loss: 0.4006 - val_accuracy: 0.6155 - val_loss: 1.2992 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9336 - loss: 0.2285 - val_accuracy: 0.5935 - val_loss: 1.4777 - learning_rate: 5.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c88fd72c10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "imgs_normalized = imgs / 255.0\n",
    "clean_imgs_train = imgs_normalized[:10000]  \n",
    "clean_labels_train = clean_labels\n",
    "noisy_imgs_train = imgs_normalized[10000:]\n",
    "noisy_labels_train = noisy_labels[10000:] \n",
    "augmenter = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # validation loss\n",
    "    factor=0.5,  # factor by which the learning rate will be reduced\n",
    "    patience=3,  # number of epochs with no improvement after which learning rate will be reduced\n",
    ")\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',  \n",
    "    monitor='val_accuracy',  # validation accuracy\n",
    "    save_best_only=True, \n",
    "    mode='max'  # decision mode \n",
    ")\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "def feature_extractor(input_shape=(32, 32, 3)):\n",
    "\n",
    "    model = models.Sequential([\n",
    "        # add a 2D convolutional layer with 32 filters, a 3x3 kernel size, ReLU activation, input shape specified, and 'same' padding\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'),\n",
    "        # add batch normalization to normalize the activations of the previous layer\n",
    "        layers.BatchNormalization(),\n",
    "        # add a max pooling layer with a 2x2 pool size to reduce spatial dimensions\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # another convolutional layer, now with 64 filters\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        # batch normalization layer after the convolution\n",
    "        layers.BatchNormalization(),\n",
    "        # another max pooling layer to further reduce dimensions\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        # third convolutional layer with 128 filters\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        # followed by batch normalization\n",
    "        layers.BatchNormalization(),\n",
    "        # global max pooling to reduce the entire feature map to a single maximum value per feature map \n",
    "        layers.GlobalMaxPooling2D(),\n",
    "    ])\n",
    "   \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def label_correction_model():\n",
    "    # input layer for the images\n",
    "    image_input = Input(shape=(32, 32, 3))\n",
    "    # input layer for the noisy labels\n",
    "    noisy_label_input = Input(shape=(10,))\n",
    "    \n",
    "    # feature extractor model \n",
    "    feature_model = feature_extractor()\n",
    "\n",
    "    image_features = feature_model(image_input)\n",
    "    \n",
    "    # combine the image features and noisy label input\n",
    "    combined_input = layers.concatenate([image_features, noisy_label_input])\n",
    "    # add a dense layer with ReLU activation on top of the combined input\n",
    "    combined_input = layers.Dense(128, activation='relu')(combined_input)\n",
    "    \n",
    "    # add a final dense layer with softmax activation to predict the corrected labels\n",
    "    corrected_labels = layers.Dense(10, activation='softmax')(combined_input)\n",
    "    \n",
    "    # create the Model object\n",
    "    model = Model(inputs=[image_input, noisy_label_input], outputs=corrected_labels)\n",
    "    # compile the model with the Adam optimizer, categorical crossentropy loss, and accuracy metric\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model2 = label_correction_model()\n",
    "clean_labels_train_cat = tf.keras.utils.to_categorical(clean_labels_train)\n",
    "noisy_labels_train_cat = tf.keras.utils.to_categorical(noisy_labels_train)\n",
    "\n",
    "\n",
    "model2.fit(\n",
    "    [clean_imgs_train, noisy_labels_train_cat], \n",
    "    clean_labels_train_cat, \n",
    "    epochs=10,  batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[lr_scheduler, model_checkpoint]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39510a",
   "metadata": {},
   "source": [
    "with kfolds(run this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "187246eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3037 - loss: 2.1779 - val_accuracy: 0.1415 - val_loss: 2.5312 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4660 - loss: 1.4585 - val_accuracy: 0.4205 - val_loss: 1.6501 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5497 - loss: 1.2373 - val_accuracy: 0.4765 - val_loss: 1.4875 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6162 - loss: 1.0794 - val_accuracy: 0.4550 - val_loss: 1.6610 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6596 - loss: 0.9532 - val_accuracy: 0.5030 - val_loss: 1.4213 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7123 - loss: 0.8071 - val_accuracy: 0.5175 - val_loss: 1.5068 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7530 - loss: 0.6947 - val_accuracy: 0.5275 - val_loss: 1.5006 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7873 - loss: 0.5880 - val_accuracy: 0.5630 - val_loss: 1.4635 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8687 - loss: 0.3924 - val_accuracy: 0.5870 - val_loss: 1.3580 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9252 - loss: 0.2277 - val_accuracy: 0.5925 - val_loss: 1.4480 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.2985 - loss: 2.0809 - val_accuracy: 0.1540 - val_loss: 2.4002 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4955 - loss: 1.4073 - val_accuracy: 0.4130 - val_loss: 1.5907 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5540 - loss: 1.2248 - val_accuracy: 0.4830 - val_loss: 1.4526 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6294 - loss: 1.0460 - val_accuracy: 0.4845 - val_loss: 1.5216 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6730 - loss: 0.9158 - val_accuracy: 0.4615 - val_loss: 1.6317 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7191 - loss: 0.8009 - val_accuracy: 0.5795 - val_loss: 1.2707 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7685 - loss: 0.6679 - val_accuracy: 0.5505 - val_loss: 1.4233 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7871 - loss: 0.6034 - val_accuracy: 0.5475 - val_loss: 1.4108 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8473 - loss: 0.4526 - val_accuracy: 0.5915 - val_loss: 1.3465 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8992 - loss: 0.3076 - val_accuracy: 0.6045 - val_loss: 1.3597 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3065 - loss: 2.0916 - val_accuracy: 0.1385 - val_loss: 2.6791 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4819 - loss: 1.4659 - val_accuracy: 0.3685 - val_loss: 1.8024 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5545 - loss: 1.2471 - val_accuracy: 0.3540 - val_loss: 1.9790 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5954 - loss: 1.1349 - val_accuracy: 0.4825 - val_loss: 1.5380 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6534 - loss: 0.9865 - val_accuracy: 0.5430 - val_loss: 1.4139 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6964 - loss: 0.8395 - val_accuracy: 0.4870 - val_loss: 1.6463 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7420 - loss: 0.7098 - val_accuracy: 0.5455 - val_loss: 1.4776 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7900 - loss: 0.5956 - val_accuracy: 0.5730 - val_loss: 1.3343 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8165 - loss: 0.5215 - val_accuracy: 0.4705 - val_loss: 2.0109 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8299 - loss: 0.4673 - val_accuracy: 0.5810 - val_loss: 1.4850 - learning_rate: 0.0010\n",
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3029 - loss: 2.0967 - val_accuracy: 0.1395 - val_loss: 2.3315 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4725 - loss: 1.4347 - val_accuracy: 0.3785 - val_loss: 1.7479 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5666 - loss: 1.2043 - val_accuracy: 0.4215 - val_loss: 1.7018 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6317 - loss: 1.0275 - val_accuracy: 0.5085 - val_loss: 1.4705 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6886 - loss: 0.8783 - val_accuracy: 0.4755 - val_loss: 1.6381 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7427 - loss: 0.7387 - val_accuracy: 0.5895 - val_loss: 1.2390 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7850 - loss: 0.6201 - val_accuracy: 0.4745 - val_loss: 1.6815 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8134 - loss: 0.5570 - val_accuracy: 0.4900 - val_loss: 1.8752 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8246 - loss: 0.5007 - val_accuracy: 0.5670 - val_loss: 1.5021 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9074 - loss: 0.2853 - val_accuracy: 0.6115 - val_loss: 1.3027 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.2957 - loss: 2.0729 - val_accuracy: 0.1625 - val_loss: 2.5801 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5054 - loss: 1.3745 - val_accuracy: 0.4135 - val_loss: 1.5918 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5756 - loss: 1.2148 - val_accuracy: 0.4960 - val_loss: 1.4727 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6362 - loss: 1.0444 - val_accuracy: 0.4800 - val_loss: 1.5033 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6687 - loss: 0.9418 - val_accuracy: 0.5235 - val_loss: 1.4502 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7236 - loss: 0.7979 - val_accuracy: 0.5630 - val_loss: 1.2958 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7584 - loss: 0.6969 - val_accuracy: 0.5395 - val_loss: 1.3989 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7907 - loss: 0.5875 - val_accuracy: 0.5730 - val_loss: 1.3349 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8356 - loss: 0.4726 - val_accuracy: 0.5615 - val_loss: 1.5695 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8929 - loss: 0.3158 - val_accuracy: 0.6035 - val_loss: 1.3138 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "imgs_normalized = imgs / 255.0\n",
    "clean_imgs_train = imgs_normalized[:10000]  \n",
    "clean_labels_train = clean_labels\n",
    "noisy_imgs_train = imgs_normalized[10000:]\n",
    "noisy_labels_train = noisy_labels[10000:] \n",
    "augmenter = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # validation loss\n",
    "    factor=0.5,  # factor by which the learning rate will be reduced\n",
    "    patience=3,  # number of epochs with no improvement after which learning rate will be reduced\n",
    ")\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',  \n",
    "    monitor='val_accuracy',  # validation accuracy\n",
    "    save_best_only=True, \n",
    "    mode='max'  # decision mode \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def feature_extractor(input_shape=(32, 32, 3)):\n",
    "\n",
    "    model = models.Sequential([\n",
    "        # add a 2D convolutional layer with 32 filters, a 3x3 kernel size, ReLU activation, input shape specified, and 'same' padding\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'),\n",
    "        # add batch normalization to normalize the activations of the previous layer\n",
    "        layers.BatchNormalization(),\n",
    "        # add a max pooling layer with a 2x2 pool size to reduce spatial dimensions\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # another convolutional layer, now with 64 filters\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        # batch normalization layer after the convolution\n",
    "        layers.BatchNormalization(),\n",
    "        # another max pooling layer to further reduce dimensions\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        # third convolutional layer with 128 filters\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        # followed by batch normalization\n",
    "        layers.BatchNormalization(),\n",
    "        # global max pooling to reduce the entire feature map to a single maximum value per feature map \n",
    "        layers.GlobalMaxPooling2D(),\n",
    "    ])\n",
    "   \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def label_correction_model():\n",
    "    # input layer for the images\n",
    "    image_input = Input(shape=(32, 32, 3))\n",
    "    # input layer for the noisy labels\n",
    "    noisy_label_input = Input(shape=(10,))\n",
    "    \n",
    "    # feature extractor model \n",
    "    feature_model = feature_extractor()\n",
    "\n",
    "    image_features = feature_model(image_input)\n",
    "    \n",
    "    # combine the image features and noisy label input\n",
    "    combined_input = layers.concatenate([image_features, noisy_label_input])\n",
    "    # add a dense layer with ReLU activation on top of the combined input\n",
    "    combined_input = layers.Dense(128, activation='relu')(combined_input)\n",
    "    \n",
    "    # add a final dense layer with softmax activation to predict the corrected labels\n",
    "    corrected_labels = layers.Dense(10, activation='softmax')(combined_input)\n",
    "    \n",
    "    # create the Model object\n",
    "    model = Model(inputs=[image_input, noisy_label_input], outputs=corrected_labels)\n",
    "    # compile the model with the Adam optimizer, categorical crossentropy loss, and accuracy metric\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model2 = label_correction_model()\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=5243)\n",
    "clean_labels_train_cat = tf.keras.utils.to_categorical(clean_labels_train)\n",
    "noisy_labels_train_cat = tf.keras.utils.to_categorical(noisy_labels_train)\n",
    "\n",
    "for train_index, val_index in kf.split(clean_imgs_train):\n",
    "    x_train, x_val = clean_imgs_train[train_index], clean_imgs_train[val_index]\n",
    "    y_train, y_val = clean_labels_train_cat[train_index], clean_labels_train_cat[val_index]\n",
    "    noisy_y_train, noisy_y_val = noisy_labels_train_cat[train_index], noisy_labels_train_cat[val_index]\n",
    "\n",
    "    model2 = label_correction_model()\n",
    "    model2.fit(\n",
    "        [x_train, noisy_y_train], y_train,\n",
    "        validation_data=([x_val, noisy_y_val], y_val),\n",
    "        epochs=10, batch_size=32,\n",
    "        callbacks=[lr_scheduler, model_checkpoint]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8868934",
   "metadata": {},
   "source": [
    "get probabilities(run this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63d5497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict labels for noisy images\n",
    "predicted_probabilities = model2.predict([noisy_imgs_train, noisy_labels_train_cat])\n",
    "\n",
    "# Convert probabilities to labels\n",
    "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
    "\n",
    "#threshold,>0.9 in any class\n",
    "confidence_threshold = 0.9\n",
    "high_confidence_indices = np.where(np.max(predicted_probabilities, axis=1) > confidence_threshold)[0]\n",
    "\n",
    "# Generate pseudo labels for high confidence predictions\n",
    "pseudo_labels = predicted_labels[high_confidence_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c2831c",
   "metadata": {},
   "source": [
    "Final model without kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcd4ea88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3676 - loss: 1.7544 - val_accuracy: 0.7153 - val_loss: 0.9043\n",
      "Epoch 2/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5967 - loss: 1.1659 - val_accuracy: 0.7800 - val_loss: 0.6767\n",
      "Epoch 3/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6553 - loss: 0.9859 - val_accuracy: 0.8107 - val_loss: 0.5940\n",
      "Epoch 4/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6956 - loss: 0.8708 - val_accuracy: 0.8179 - val_loss: 0.5348\n",
      "Epoch 5/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7248 - loss: 0.7901 - val_accuracy: 0.8227 - val_loss: 0.5407\n",
      "Epoch 6/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.7392 - val_accuracy: 0.8252 - val_loss: 0.5259\n",
      "Epoch 7/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7650 - loss: 0.6748 - val_accuracy: 0.8318 - val_loss: 0.5070\n",
      "Epoch 8/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7744 - loss: 0.6283 - val_accuracy: 0.8427 - val_loss: 0.4823\n",
      "Epoch 9/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7960 - loss: 0.5765 - val_accuracy: 0.8377 - val_loss: 0.4974\n",
      "Epoch 10/10\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8004 - loss: 0.5556 - val_accuracy: 0.8421 - val_loss: 0.5033\n",
      "313/313 - 1s - 2ms/step - accuracy: 0.8424 - loss: 0.4564\n",
      "Test Loss: 0.45636677742004395\n",
      "Test Accuracy: 0.8424000144004822\n",
      "Runtime of the first part: 73.97592520713806 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_final_model(input_shape=(32, 32, 3), num_classes=10):\n",
    "  \n",
    "    model = models.Sequential([\n",
    "        # add a convolutional layer with 24 filters, a 3x3 kernel, ReLU activation, and 'same' padding\n",
    "        layers.Conv2D(24, (3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "        # another convolutional layer with 24 filters and ReLU activation without padding specification\n",
    "        layers.Conv2D(24, (3, 3), activation='relu'),\n",
    "        # max pooling layer to reduce the spatial dimensions by taking the maximum value over a 2x2 pooling window\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # another block of convolutional and max pooling layers, this time with 48 filters\n",
    "        layers.Conv2D(48, (3, 3), padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # flatten the 3D output to 1D to feed into the dense layer\n",
    "        layers.Flatten(),\n",
    "        # dense layer with 128 neurons and ReLU activation\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        # dropout layer to reduce overfitting by randomly setting a fraction of inputs to 0\n",
    "        layers.Dropout(0.5),\n",
    "        # final dense layer with a softmax activation, outputting probabilities for each class\n",
    "        layers.Dense(num_classes, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    # compile the model with the Adam optimizer, sparse categorical crossentropy as the loss function, and accuracy \n",
    "    model.compile(optimizer=Adam(0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "   \n",
    "    return model\n",
    "\n",
    "\n",
    "x_train_combined = np.concatenate([clean_imgs_train, noisy_imgs_train[high_confidence_indices]])\n",
    "y_train_combined = np.concatenate([clean_labels, pseudo_labels]) \n",
    "\n",
    "# Train the final model\n",
    "final_model = build_final_model()\n",
    "final_model.fit(x_train_combined, y_train_combined, epochs=10, validation_split=0.2, batch_size=16)\n",
    "\n",
    "x_test = imgs[:10000] / 255.0  \n",
    "y_test = clean_labels\n",
    "test_loss, test_accuracy = final_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Runtime of the first part: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bb048e-3cc7-4119-b523-10f8360a9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0381df53",
   "metadata": {},
   "source": [
    "Final model with kfolds(40k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c5e0577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3750 - loss: 1.7068 - val_accuracy: 0.6902 - val_loss: 0.8994 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6625 - loss: 0.9812 - val_accuracy: 0.7775 - val_loss: 0.6476 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7264 - loss: 0.7906 - val_accuracy: 0.8053 - val_loss: 0.5691 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7697 - loss: 0.6788 - val_accuracy: 0.8222 - val_loss: 0.5188 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8095 - loss: 0.5446 - val_accuracy: 0.8269 - val_loss: 0.5089 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.4772 - val_accuracy: 0.8374 - val_loss: 0.5121 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8585 - loss: 0.4179 - val_accuracy: 0.8447 - val_loss: 0.4726 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8646 - loss: 0.3982 - val_accuracy: 0.8467 - val_loss: 0.4857 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8817 - loss: 0.3331 - val_accuracy: 0.8546 - val_loss: 0.4674 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8972 - loss: 0.2942 - val_accuracy: 0.8394 - val_loss: 0.5363 - learning_rate: 0.0010\n",
      "Epoch 1/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3712 - loss: 1.7054 - val_accuracy: 0.6823 - val_loss: 0.9082 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6425 - loss: 1.0195 - val_accuracy: 0.7428 - val_loss: 0.7649 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7223 - loss: 0.8102 - val_accuracy: 0.7673 - val_loss: 0.6555 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7634 - loss: 0.6911 - val_accuracy: 0.7907 - val_loss: 0.6020 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7921 - loss: 0.6064 - val_accuracy: 0.8047 - val_loss: 0.5797 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8189 - loss: 0.5330 - val_accuracy: 0.8105 - val_loss: 0.5498 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.4928 - val_accuracy: 0.8304 - val_loss: 0.5051 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.4318 - val_accuracy: 0.7947 - val_loss: 0.6453 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8601 - loss: 0.4023 - val_accuracy: 0.8079 - val_loss: 0.5845 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.3569 - val_accuracy: 0.8266 - val_loss: 0.5300 - learning_rate: 0.0010\n",
      "Epoch 1/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3941 - loss: 1.6706 - val_accuracy: 0.6416 - val_loss: 1.0266 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6649 - loss: 0.9598 - val_accuracy: 0.7456 - val_loss: 0.7375 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7258 - loss: 0.7849 - val_accuracy: 0.7780 - val_loss: 0.6536 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7787 - loss: 0.6425 - val_accuracy: 0.7815 - val_loss: 0.6213 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.5917 - val_accuracy: 0.8037 - val_loss: 0.5646 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.5107 - val_accuracy: 0.8195 - val_loss: 0.5301 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8444 - loss: 0.4513 - val_accuracy: 0.8175 - val_loss: 0.5416 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8574 - loss: 0.4012 - val_accuracy: 0.8210 - val_loss: 0.5275 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8771 - loss: 0.3445 - val_accuracy: 0.7599 - val_loss: 0.8014 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.3527 - val_accuracy: 0.8289 - val_loss: 0.5601 - learning_rate: 0.0010\n",
      "Epoch 1/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3814 - loss: 1.6839 - val_accuracy: 0.6966 - val_loss: 0.8996 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6499 - loss: 1.0132 - val_accuracy: 0.7398 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7152 - loss: 0.8153 - val_accuracy: 0.7757 - val_loss: 0.6477 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7634 - loss: 0.6959 - val_accuracy: 0.8145 - val_loss: 0.5554 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7914 - loss: 0.6164 - val_accuracy: 0.8163 - val_loss: 0.5552 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.5454 - val_accuracy: 0.8148 - val_loss: 0.5385 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8214 - loss: 0.5064 - val_accuracy: 0.8303 - val_loss: 0.5163 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8563 - loss: 0.4080 - val_accuracy: 0.8274 - val_loss: 0.5122 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8688 - loss: 0.3752 - val_accuracy: 0.8306 - val_loss: 0.5325 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8848 - loss: 0.3366 - val_accuracy: 0.8145 - val_loss: 0.6072 - learning_rate: 0.0010\n",
      "Epoch 1/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3868 - loss: 1.6940 - val_accuracy: 0.7006 - val_loss: 0.8649 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6541 - loss: 0.9925 - val_accuracy: 0.7561 - val_loss: 0.7049 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7218 - loss: 0.8042 - val_accuracy: 0.7923 - val_loss: 0.6168 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7728 - loss: 0.6651 - val_accuracy: 0.8011 - val_loss: 0.5848 - learning_rate: 0.0010\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7948 - loss: 0.5990 - val_accuracy: 0.8178 - val_loss: 0.5256 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8162 - loss: 0.5232 - val_accuracy: 0.8306 - val_loss: 0.5016 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8326 - loss: 0.4665 - val_accuracy: 0.8166 - val_loss: 0.5569 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8523 - loss: 0.4243 - val_accuracy: 0.8210 - val_loss: 0.5469 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8683 - loss: 0.3808 - val_accuracy: 0.8265 - val_loss: 0.5412 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m857/857\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8960 - loss: 0.2908 - val_accuracy: 0.8417 - val_loss: 0.5063 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "def build_final_model(input_shape=(32, 32, 3), num_classes=10):\n",
    "  \n",
    "    model = models.Sequential([\n",
    "        # add a convolutional layer with 24 filters, a 3x3 kernel, ReLU activation, and 'same' padding\n",
    "        layers.Conv2D(24, (3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "        # another convolutional layer with 24 filters and ReLU activation without padding specification\n",
    "        layers.Conv2D(24, (3, 3), activation='relu'),\n",
    "        # max pooling layer to reduce the spatial dimensions by taking the maximum value over a 2x2 pooling window\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # another block of convolutional and max pooling layers, this time with 48 filters\n",
    "        layers.Conv2D(48, (3, 3), padding='same', activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # flatten the 3D output to 1D to feed into the dense layer\n",
    "        layers.Flatten(),\n",
    "        # dense layer with 128 neurons and ReLU activation\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        # dropout layer to reduce overfitting by randomly setting a fraction of inputs to 0\n",
    "        layers.Dropout(0.5),\n",
    "        # final dense layer with a softmax activation, outputting probabilities for each class\n",
    "        layers.Dense(num_classes, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    # compile the model with the Adam optimizer, sparse categorical crossentropy as the loss function, and accuracy \n",
    "    model.compile(optimizer=Adam(0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "   \n",
    "    return model\n",
    "kf_combined = KFold(n_splits=5, shuffle=True, random_state=5243)\n",
    "\n",
    "x_train_combined = np.concatenate([ noisy_imgs_train[high_confidence_indices]])\n",
    "y_train_combined = np.concatenate([ pseudo_labels]) \n",
    "for train_index, val_index in kf_combined.split(x_train_combined):\n",
    "\n",
    "    x_train, x_val = x_train_combined[train_index], x_train_combined[val_index]\n",
    "    y_train, y_val = y_train_combined[train_index], y_train_combined[val_index]\n",
    "\n",
    "    final_model = build_final_model()\n",
    "    final_model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=10, batch_size=16,\n",
    "        callbacks=[lr_scheduler, model_checkpoint] \n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7d0be8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - 2ms/step - accuracy: 0.6265 - loss: 1.4245\n",
      "Test Loss: 1.424457311630249\n",
      "Test Accuracy: 0.6265000104904175\n"
     ]
    }
   ],
   "source": [
    "x_test = imgs[:10000] / 255.0  \n",
    "y_test = clean_labels\n",
    "test_loss, test_accuracy = final_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d946991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "final_model.save(\"model2_40k.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc539fb",
   "metadata": {},
   "source": [
    "final_model_with_lstm(run this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6c11677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.3652 - loss: 1.7364 - val_accuracy: 0.6292 - val_loss: 1.0547 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6507 - loss: 1.0105 - val_accuracy: 0.7220 - val_loss: 0.8137 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7465 - loss: 0.7597 - val_accuracy: 0.7258 - val_loss: 0.7954 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.6083 - val_accuracy: 0.7412 - val_loss: 0.7796 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8348 - loss: 0.4991 - val_accuracy: 0.7482 - val_loss: 0.7664 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8735 - loss: 0.3881 - val_accuracy: 0.7583 - val_loss: 0.8003 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9068 - loss: 0.2851 - val_accuracy: 0.7496 - val_loss: 0.8765 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9293 - loss: 0.2147 - val_accuracy: 0.7480 - val_loss: 0.9776 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9635 - loss: 0.1139 - val_accuracy: 0.7650 - val_loss: 1.0531 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.0649 - val_accuracy: 0.7585 - val_loss: 1.1320 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.3697 - loss: 1.7149 - val_accuracy: 0.6351 - val_loss: 1.0817 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6742 - loss: 0.9635 - val_accuracy: 0.7149 - val_loss: 0.8247 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7528 - loss: 0.7449 - val_accuracy: 0.7515 - val_loss: 0.7355 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.5935 - val_accuracy: 0.7472 - val_loss: 0.7770 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8408 - loss: 0.4761 - val_accuracy: 0.7466 - val_loss: 0.7612 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8834 - loss: 0.3577 - val_accuracy: 0.7505 - val_loss: 0.8317 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9274 - loss: 0.2233 - val_accuracy: 0.7595 - val_loss: 0.9230 - learning_rate: 5.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9602 - loss: 0.1311 - val_accuracy: 0.7555 - val_loss: 0.9653 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9727 - loss: 0.0920 - val_accuracy: 0.7563 - val_loss: 1.1084 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0517 - val_accuracy: 0.7634 - val_loss: 1.1653 - learning_rate: 2.5000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.3688 - loss: 1.7367 - val_accuracy: 0.6274 - val_loss: 1.0735 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6621 - loss: 0.9688 - val_accuracy: 0.7337 - val_loss: 0.7979 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7579 - loss: 0.7267 - val_accuracy: 0.7194 - val_loss: 0.8253 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8017 - loss: 0.5900 - val_accuracy: 0.7452 - val_loss: 0.7699 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8448 - loss: 0.4660 - val_accuracy: 0.7591 - val_loss: 0.7904 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8821 - loss: 0.3533 - val_accuracy: 0.7527 - val_loss: 0.8464 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9148 - loss: 0.2627 - val_accuracy: 0.7448 - val_loss: 0.9590 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9527 - loss: 0.1423 - val_accuracy: 0.7652 - val_loss: 0.9621 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9739 - loss: 0.0852 - val_accuracy: 0.7674 - val_loss: 1.1148 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.0624 - val_accuracy: 0.7571 - val_loss: 1.2082 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.3743 - loss: 1.7167 - val_accuracy: 0.6289 - val_loss: 1.0578 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6492 - loss: 1.0244 - val_accuracy: 0.7215 - val_loss: 0.7992 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7360 - loss: 0.7876 - val_accuracy: 0.7575 - val_loss: 0.7292 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7916 - loss: 0.6223 - val_accuracy: 0.7639 - val_loss: 0.7205 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 0.4894 - val_accuracy: 0.7617 - val_loss: 0.7394 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8743 - loss: 0.3692 - val_accuracy: 0.7534 - val_loss: 0.8197 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9086 - loss: 0.2761 - val_accuracy: 0.7556 - val_loss: 0.8959 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9573 - loss: 0.1405 - val_accuracy: 0.7712 - val_loss: 0.9296 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.0846 - val_accuracy: 0.7672 - val_loss: 1.0644 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9782 - loss: 0.0684 - val_accuracy: 0.7738 - val_loss: 1.0990 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.3589 - loss: 1.7390 - val_accuracy: 0.6388 - val_loss: 1.0086 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6716 - loss: 0.9520 - val_accuracy: 0.7296 - val_loss: 0.7753 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7494 - loss: 0.7378 - val_accuracy: 0.7165 - val_loss: 0.8304 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7928 - loss: 0.6165 - val_accuracy: 0.7195 - val_loss: 0.8571 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8375 - loss: 0.4752 - val_accuracy: 0.7520 - val_loss: 0.7677 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8871 - loss: 0.3500 - val_accuracy: 0.7534 - val_loss: 0.8041 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9192 - loss: 0.2545 - val_accuracy: 0.7458 - val_loss: 0.9067 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9333 - loss: 0.2000 - val_accuracy: 0.7550 - val_loss: 0.9600 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9634 - loss: 0.1150 - val_accuracy: 0.7704 - val_loss: 1.0310 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1240/1240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0573 - val_accuracy: 0.7603 - val_loss: 1.1406 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, Input, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_final_model_with_lstm(input_shape=(32, 32, 3), num_classes=10):\n",
    "    # input layer\n",
    "    image_input = Input(shape=input_shape)\n",
    "    \n",
    "    # convolutional layers\n",
    "    x = layers.Conv2D(24, (3, 3), padding='same', activation='relu')(image_input)\n",
    "    x = layers.Conv2D(24, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(48, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    #  LSTM layer\n",
    "\n",
    " \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Reshape((1, -1))(x)  \n",
    "    # LSTM layer\n",
    "    x = layers.LSTM(64)(x)\n",
    "\n",
    "    # Dense layers\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "\n",
    "    model = Model(inputs=image_input, outputs=output)\n",
    "    \n",
    "  \n",
    "    model.compile(optimizer=Adam(0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "x_train_combined = np.concatenate([clean_imgs_train, noisy_imgs_train[high_confidence_indices]])\n",
    "y_train_combined = np.concatenate([clean_labels, pseudo_labels]) \n",
    "kf_combined = KFold(n_splits=5, shuffle=True, random_state=5243)\n",
    "\n",
    "for train_index, val_index in kf_combined.split(x_train_combined):\n",
    "\n",
    "    x_train, x_val = x_train_combined[train_index], x_train_combined[val_index]\n",
    "    y_train, y_val = y_train_combined[train_index], y_train_combined[val_index]\n",
    "\n",
    "    final_model =build_final_model_with_lstm()\n",
    "    final_model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=10, batch_size=16,\n",
    "        callbacks=[lr_scheduler, model_checkpoint] \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dff7abad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - 3ms/step - accuracy: 0.9184 - loss: 0.4016\n",
      "Test Loss: 0.4015614688396454\n",
      "Test Accuracy: 0.91839998960495\n",
      "Runtime of the first part: 382.7691671848297 seconds\n"
     ]
    }
   ],
   "source": [
    "x_test = imgs[:10000] / 255.0  \n",
    "y_test = clean_labels\n",
    "test_loss, test_accuracy = final_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Runtime of the first part: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40aad239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "final_model.save(\"model2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb95b8-9611-42f7-85fd-6fa48f7a0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "\n",
    "    n_test = 1000\n",
    "    test_imgs = np.empty((n_test, 32, 32, 3), dtype=np.float32)\n",
    "    \n",
    "    for i in range(n_test):\n",
    "        img_fn = f'../data/images/{i+1:05d}.png'\n",
    "        img = cv2.imread(img_fn)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255.0  \n",
    "        test_imgs[i] = img\n",
    "def model_II(image):\n",
    "\n",
    "\n",
    "\n",
    "    final_model = load_model(\"model2_eva.hdf5\")\n",
    "\n",
    "    predicted_probabilities = final_model.predict(image)\n",
    "    \n",
    "    model2_label= np.argmax(predicted_probabilities, axis=1)\n",
    "    return model2_label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a8ce9-d167-4f0a-b981-5763a15bd1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123a3ff-09bb-4958-9a89-ea4691bed126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8fd4d3-424c-44d1-aadc-3a5e5df76b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9cd1fe-7090-42c3-a101-caaab5eab0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cdb7a3b",
   "metadata": {},
   "source": [
    "without combine the true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2f8a4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4295 - loss: 1.6008 - val_accuracy: 0.7076 - val_loss: 0.8560 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7137 - loss: 0.8540 - val_accuracy: 0.7880 - val_loss: 0.6213 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7913 - loss: 0.6243 - val_accuracy: 0.7849 - val_loss: 0.6224 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8440 - loss: 0.4785 - val_accuracy: 0.8063 - val_loss: 0.5995 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8699 - loss: 0.3687 - val_accuracy: 0.8178 - val_loss: 0.5561 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9079 - loss: 0.2758 - val_accuracy: 0.8211 - val_loss: 0.5858 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9327 - loss: 0.2002 - val_accuracy: 0.8233 - val_loss: 0.6041 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9576 - loss: 0.1320 - val_accuracy: 0.8225 - val_loss: 0.7088 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9800 - loss: 0.0694 - val_accuracy: 0.8317 - val_loss: 0.7211 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0301 - val_accuracy: 0.8344 - val_loss: 0.7769 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4382 - loss: 1.5924 - val_accuracy: 0.6789 - val_loss: 0.9322 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7186 - loss: 0.8282 - val_accuracy: 0.7613 - val_loss: 0.7029 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7967 - loss: 0.6102 - val_accuracy: 0.7969 - val_loss: 0.6013 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8458 - loss: 0.4707 - val_accuracy: 0.8133 - val_loss: 0.5554 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8784 - loss: 0.3578 - val_accuracy: 0.7999 - val_loss: 0.6243 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9122 - loss: 0.2564 - val_accuracy: 0.8211 - val_loss: 0.6163 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 0.1806 - val_accuracy: 0.8075 - val_loss: 0.6976 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9724 - loss: 0.0926 - val_accuracy: 0.8322 - val_loss: 0.6745 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0458 - val_accuracy: 0.8278 - val_loss: 0.7509 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9836 - loss: 0.0505 - val_accuracy: 0.8314 - val_loss: 0.7913 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4486 - loss: 1.5553 - val_accuracy: 0.6733 - val_loss: 0.9523 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7267 - loss: 0.8135 - val_accuracy: 0.7723 - val_loss: 0.6687 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 0.5962 - val_accuracy: 0.8105 - val_loss: 0.5834 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.4463 - val_accuracy: 0.7974 - val_loss: 0.6546 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8793 - loss: 0.3509 - val_accuracy: 0.8233 - val_loss: 0.5757 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2526 - val_accuracy: 0.8344 - val_loss: 0.5571 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 0.1882 - val_accuracy: 0.8188 - val_loss: 0.6671 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9570 - loss: 0.1358 - val_accuracy: 0.8099 - val_loss: 0.7223 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9662 - loss: 0.1042 - val_accuracy: 0.7927 - val_loss: 0.8489 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.0602 - val_accuracy: 0.8299 - val_loss: 0.8114 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4347 - loss: 1.6151 - val_accuracy: 0.7122 - val_loss: 0.8418 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7393 - loss: 0.7777 - val_accuracy: 0.7832 - val_loss: 0.6295 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8121 - loss: 0.5644 - val_accuracy: 0.8141 - val_loss: 0.5573 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8524 - loss: 0.4305 - val_accuracy: 0.8208 - val_loss: 0.5441 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8899 - loss: 0.3238 - val_accuracy: 0.8169 - val_loss: 0.6067 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9217 - loss: 0.2388 - val_accuracy: 0.8107 - val_loss: 0.6507 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.1632 - val_accuracy: 0.8299 - val_loss: 0.6397 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9766 - loss: 0.0750 - val_accuracy: 0.8358 - val_loss: 0.7112 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.0383 - val_accuracy: 0.8263 - val_loss: 0.8015 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0383 - val_accuracy: 0.8230 - val_loss: 0.8746 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4305 - loss: 1.6127 - val_accuracy: 0.7367 - val_loss: 0.7918 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.7805 - val_accuracy: 0.7615 - val_loss: 0.6896 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8110 - loss: 0.5635 - val_accuracy: 0.7757 - val_loss: 0.6645 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8540 - loss: 0.4411 - val_accuracy: 0.8002 - val_loss: 0.5952 - learning_rate: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8830 - loss: 0.3440 - val_accuracy: 0.8194 - val_loss: 0.5630 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9128 - loss: 0.2486 - val_accuracy: 0.7481 - val_loss: 0.9194 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9285 - loss: 0.2189 - val_accuracy: 0.8024 - val_loss: 0.7002 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9569 - loss: 0.1399 - val_accuracy: 0.8068 - val_loss: 0.7686 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9755 - loss: 0.0774 - val_accuracy: 0.8266 - val_loss: 0.7483 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m899/899\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0334 - val_accuracy: 0.8322 - val_loss: 0.7793 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, Input, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_final_model_with_lstm(input_shape=(32, 32, 3), num_classes=10):\n",
    "    # input layer\n",
    "    image_input = Input(shape=input_shape)\n",
    "    \n",
    "    # convolutional layers\n",
    "    x = layers.Conv2D(24, (3, 3), padding='same', activation='relu')(image_input)\n",
    "    x = layers.Conv2D(24, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(48, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    #  LSTM layer\n",
    "\n",
    " \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Reshape((1, -1))(x)  \n",
    "    # LSTM layer\n",
    "    x = layers.LSTM(64)(x)\n",
    "\n",
    "    # Dense layers\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "\n",
    "    model = Model(inputs=image_input, outputs=output)\n",
    "    \n",
    "  \n",
    "    model.compile(optimizer=Adam(0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "x_train_combined = np.concatenate([ noisy_imgs_train[high_confidence_indices]])\n",
    "y_train_combined = np.concatenate([pseudo_labels]) \n",
    "kf_combined = KFold(n_splits=5, shuffle=True, random_state=5243)\n",
    "\n",
    "for train_index, val_index in kf_combined.split(x_train_combined):\n",
    "\n",
    "    x_train, x_val = x_train_combined[train_index], x_train_combined[val_index]\n",
    "    y_train, y_val = y_train_combined[train_index], y_train_combined[val_index]\n",
    "\n",
    "    final_model =build_final_model_with_lstm()\n",
    "    final_model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=10, batch_size=16,\n",
    "        callbacks=[lr_scheduler, model_checkpoint] \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a407efd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - 2ms/step - accuracy: 0.5866 - loss: 2.3986\n",
      "Test Loss: 2.3985815048217773\n",
      "Test Accuracy: 0.5866000056266785\n"
     ]
    }
   ],
   "source": [
    "x_test = imgs[:10000] / 255.0  \n",
    "y_test = clean_labels\n",
    "test_loss, test_accuracy = final_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88525b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b85b664b",
   "metadata": {},
   "source": [
    " self-attention mechanism + use advanced convolutional layer types+ Dense connections ( DenseNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7789067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 295ms/step - accuracy: 0.4398 - loss: 1.6054 - val_accuracy: 0.5625 - val_loss: 1.2721 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 295ms/step - accuracy: 0.6559 - loss: 0.9974 - val_accuracy: 0.6860 - val_loss: 0.8999 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 298ms/step - accuracy: 0.7221 - loss: 0.8093 - val_accuracy: 0.6683 - val_loss: 1.0173 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 297ms/step - accuracy: 0.7560 - loss: 0.7171 - val_accuracy: 0.7431 - val_loss: 0.7503 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 297ms/step - accuracy: 0.7772 - loss: 0.6460 - val_accuracy: 0.6306 - val_loss: 1.0941 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 299ms/step - accuracy: 0.7910 - loss: 0.6075 - val_accuracy: 0.6111 - val_loss: 1.3974 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 299ms/step - accuracy: 0.8137 - loss: 0.5505 - val_accuracy: 0.7823 - val_loss: 0.6344 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 300ms/step - accuracy: 0.8281 - loss: 0.5162 - val_accuracy: 0.7077 - val_loss: 0.9408 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 298ms/step - accuracy: 0.8338 - loss: 0.4823 - val_accuracy: 0.7527 - val_loss: 0.7695 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 299ms/step - accuracy: 0.8474 - loss: 0.4379 - val_accuracy: 0.7532 - val_loss: 0.8166 - learning_rate: 0.0010\n",
      "Epoch 1/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 297ms/step - accuracy: 0.4214 - loss: 1.6753 - val_accuracy: 0.4049 - val_loss: 2.2131 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 295ms/step - accuracy: 0.6568 - loss: 1.0064 - val_accuracy: 0.7036 - val_loss: 0.8631 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 297ms/step - accuracy: 0.7140 - loss: 0.8403 - val_accuracy: 0.7022 - val_loss: 0.8776 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 297ms/step - accuracy: 0.7542 - loss: 0.7301 - val_accuracy: 0.6831 - val_loss: 0.9463 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 296ms/step - accuracy: 0.7816 - loss: 0.6631 - val_accuracy: 0.7222 - val_loss: 0.8815 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 297ms/step - accuracy: 0.8168 - loss: 0.5374 - val_accuracy: 0.7787 - val_loss: 0.6648 - learning_rate: 5.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 298ms/step - accuracy: 0.8325 - loss: 0.4935 - val_accuracy: 0.7794 - val_loss: 0.6667 - learning_rate: 5.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 297ms/step - accuracy: 0.8443 - loss: 0.4557 - val_accuracy: 0.7023 - val_loss: 0.9951 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 297ms/step - accuracy: 0.8592 - loss: 0.4126 - val_accuracy: 0.7702 - val_loss: 0.7194 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m874/874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 296ms/step - accuracy: 0.8827 - loss: 0.3375 - val_accuracy: 0.8156 - val_loss: 0.5726 - learning_rate: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, Input, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def ConvBlock(x, filters, kernel_size, strides=(1, 1)):  ## promote code reuse and modularity\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=strides, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def DenseBlock(x, growth_rate, layers_in_block):  ##Multiple convolutional layers where each layer receives feature maps from all preceding layers, promoting feature reuse\n",
    "    for i in range(layers_in_block):\n",
    "        cb = ConvBlock(x, growth_rate, (3, 3))\n",
    "        x = layers.Concatenate(axis=-1)([x, cb])\n",
    "    return x\n",
    "\n",
    "def TransitionLayer(x, reduction):  ## Used between Dense Blocks, they help in compression and reducing the dimensionality of feature maps\n",
    "    reduced_filters = int(tf.keras.backend.int_shape(x)[-1] * reduction)\n",
    "    x = ConvBlock(x, reduced_filters, (1, 1))\n",
    "    x = layers.AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
    "    return x\n",
    "\n",
    "def build_model(input_shape=(32, 32, 3), num_classes=10, growth_rate=32, dense_blocks=[6, 12, 24], reduction=0.5):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Initial Convolution\n",
    "    x = ConvBlock(inputs, growth_rate * 2, (3, 3))\n",
    "    \n",
    "    # Dense Blocks with Transition Layers\n",
    "    for i, layers_in_block in enumerate(dense_blocks):\n",
    "        x = DenseBlock(x, growth_rate, layers_in_block)\n",
    "        if i < len(dense_blocks) - 1:  #  if no transition after the last block\n",
    "            x = TransitionLayer(x, reduction)\n",
    "    \n",
    "    # Global Average Pooling before prediction layer\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Prediction Layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "x_train_combined = np.concatenate([clean_imgs_train, noisy_imgs_train[high_confidence_indices]])\n",
    "y_train_combined = np.concatenate([clean_labels, pseudo_labels])\n",
    "kf_combined = KFold(n_splits=2, shuffle=True, random_state=5243)\n",
    "\n",
    "for train_index, val_index in kf_combined.split(x_train_combined):\n",
    "\n",
    "    x_train, x_val = x_train_combined[train_index], x_train_combined[val_index]\n",
    "    y_train, y_val = y_train_combined[train_index], y_train_combined[val_index]\n",
    "\n",
    "    final_model =build_model()\n",
    "    final_model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=10, batch_size=16,\n",
    "        callbacks=[lr_scheduler, model_checkpoint] \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcef4e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 39s - 125ms/step - accuracy: 0.7832 - loss: 0.6613\n",
      "Test Loss: 0.661315381526947\n",
      "Test Accuracy: 0.7832000255584717\n"
     ]
    }
   ],
   "source": [
    "x_test = imgs[:10000] / 255.0  \n",
    "y_test = clean_labels\n",
    "test_loss, test_accuracy = final_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22b966a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "final_model.save(\"model2_ultimate.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d30a4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b6ae24-e42c-48f9-8a88-e8c69c7089bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70127d18-f7f3-4267-a9b2-688cf47af374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8650ec20-c428-4842-8e5f-fa521032ce1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4c4eb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "final_model.save(\"model2.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea5a7b",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb9581",
   "metadata": {},
   "source": [
    "For assessment, we will evaluate your final model on a hidden test dataset with clean labels by the `evaluation` function defined as follows. Although you will not have the access to the test set, the function would be useful for the model developments. For example, you can split the small training set, using one portion for weakly supervised learning and the other for validation purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea622e71-fbce-4645-a09e-76d4912d1c4f",
   "metadata": {},
   "source": [
    "take 1000 out from 10000 true label. Evaulate model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e63802f5-088c-44be-ae95-449976d25274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.2991 - loss: 2.0984 - val_accuracy: 0.1444 - val_loss: 2.4279 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4621 - loss: 1.4964 - val_accuracy: 0.4117 - val_loss: 1.6558 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5398 - loss: 1.2721 - val_accuracy: 0.4344 - val_loss: 1.6206 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6056 - loss: 1.1089 - val_accuracy: 0.5428 - val_loss: 1.2707 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6514 - loss: 0.9880 - val_accuracy: 0.4678 - val_loss: 1.6631 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6941 - loss: 0.8768 - val_accuracy: 0.5233 - val_loss: 1.3787 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7360 - loss: 0.7482 - val_accuracy: 0.5078 - val_loss: 1.4814 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8018 - loss: 0.5685 - val_accuracy: 0.6006 - val_loss: 1.2219 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8773 - loss: 0.3824 - val_accuracy: 0.5811 - val_loss: 1.2672 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9081 - loss: 0.2961 - val_accuracy: 0.5972 - val_loss: 1.3025 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.2939 - loss: 2.1623 - val_accuracy: 0.1339 - val_loss: 2.3788 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4954 - loss: 1.4034 - val_accuracy: 0.3094 - val_loss: 1.9825 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5680 - loss: 1.2173 - val_accuracy: 0.4217 - val_loss: 1.7862 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6235 - loss: 1.0448 - val_accuracy: 0.4244 - val_loss: 1.9287 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6741 - loss: 0.9173 - val_accuracy: 0.5172 - val_loss: 1.4397 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7365 - loss: 0.7584 - val_accuracy: 0.4756 - val_loss: 1.8958 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7840 - loss: 0.6295 - val_accuracy: 0.4017 - val_loss: 2.1943 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7945 - loss: 0.5968 - val_accuracy: 0.4850 - val_loss: 1.7205 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8823 - loss: 0.3656 - val_accuracy: 0.5311 - val_loss: 1.6315 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9306 - loss: 0.2238 - val_accuracy: 0.6050 - val_loss: 1.3135 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.3040 - loss: 2.0878 - val_accuracy: 0.0894 - val_loss: 3.1275 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4825 - loss: 1.4427 - val_accuracy: 0.1939 - val_loss: 2.3119 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5656 - loss: 1.2145 - val_accuracy: 0.4394 - val_loss: 1.5608 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6232 - loss: 1.0665 - val_accuracy: 0.5278 - val_loss: 1.3809 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6929 - loss: 0.8827 - val_accuracy: 0.3633 - val_loss: 2.3270 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7077 - loss: 0.8294 - val_accuracy: 0.5167 - val_loss: 1.4250 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7644 - loss: 0.6597 - val_accuracy: 0.4311 - val_loss: 2.1193 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8448 - loss: 0.4717 - val_accuracy: 0.5911 - val_loss: 1.3779 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9071 - loss: 0.2923 - val_accuracy: 0.5928 - val_loss: 1.3941 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9395 - loss: 0.2013 - val_accuracy: 0.5983 - val_loss: 1.4458 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.2810 - loss: 2.2359 - val_accuracy: 0.1233 - val_loss: 2.8442 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4831 - loss: 1.4248 - val_accuracy: 0.4139 - val_loss: 1.6601 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5728 - loss: 1.2297 - val_accuracy: 0.5556 - val_loss: 1.2884 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6159 - loss: 1.0651 - val_accuracy: 0.5250 - val_loss: 1.3464 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6776 - loss: 0.9291 - val_accuracy: 0.4750 - val_loss: 1.6139 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7241 - loss: 0.7824 - val_accuracy: 0.4672 - val_loss: 1.6578 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7989 - loss: 0.5880 - val_accuracy: 0.5439 - val_loss: 1.4569 - learning_rate: 5.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8700 - loss: 0.3885 - val_accuracy: 0.5733 - val_loss: 1.4078 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9132 - loss: 0.2761 - val_accuracy: 0.5928 - val_loss: 1.4311 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9429 - loss: 0.2004 - val_accuracy: 0.6100 - val_loss: 1.3299 - learning_rate: 2.5000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.2935 - loss: 2.2063 - val_accuracy: 0.1472 - val_loss: 2.4771 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4868 - loss: 1.4235 - val_accuracy: 0.3583 - val_loss: 1.8052 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5650 - loss: 1.2138 - val_accuracy: 0.3678 - val_loss: 1.9037 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6148 - loss: 1.0808 - val_accuracy: 0.4878 - val_loss: 1.5622 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6607 - loss: 0.9378 - val_accuracy: 0.4772 - val_loss: 1.5865 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7270 - loss: 0.7681 - val_accuracy: 0.5389 - val_loss: 1.3794 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7838 - loss: 0.6404 - val_accuracy: 0.5822 - val_loss: 1.3013 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7984 - loss: 0.5903 - val_accuracy: 0.5467 - val_loss: 1.5120 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8400 - loss: 0.4615 - val_accuracy: 0.4922 - val_loss: 1.8403 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8605 - loss: 0.3947 - val_accuracy: 0.5633 - val_loss: 1.5800 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "imgs_normalized = imgs / 255.0\n",
    "clean_imgs_train = imgs_normalized[1000:10000]  \n",
    "clean_labels_train = clean_labels[1000:10000]  \n",
    "noisy_imgs_train = imgs_normalized[10000:]\n",
    "noisy_labels_train = noisy_labels[10000:] \n",
    "augmenter = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # validation loss\n",
    "    factor=0.5,  # factor by which the learning rate will be reduced\n",
    "    patience=3,  # number of epochs with no improvement after which learning rate will be reduced\n",
    ")\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',  \n",
    "    monitor='val_accuracy',  # validation accuracy\n",
    "    save_best_only=True, \n",
    "    mode='max'  # decision mode \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def feature_extractor(input_shape=(32, 32, 3)):\n",
    "\n",
    "    model = models.Sequential([\n",
    "        # add a 2D convolutional layer with 32 filters, a 3x3 kernel size, ReLU activation, input shape specified, and 'same' padding\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'),\n",
    "        # add batch normalization to normalize the activations of the previous layer\n",
    "        layers.BatchNormalization(),\n",
    "        # add a max pooling layer with a 2x2 pool size to reduce spatial dimensions\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # another convolutional layer, now with 64 filters\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        # batch normalization layer after the convolution\n",
    "        layers.BatchNormalization(),\n",
    "        # another max pooling layer to further reduce dimensions\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        # third convolutional layer with 128 filters\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        # followed by batch normalization\n",
    "        layers.BatchNormalization(),\n",
    "        # global max pooling to reduce the entire feature map to a single maximum value per feature map \n",
    "        layers.GlobalMaxPooling2D(),\n",
    "    ])\n",
    "   \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def label_correction_model():\n",
    "    # input layer for the images\n",
    "    image_input = Input(shape=(32, 32, 3))\n",
    "    # input layer for the noisy labels\n",
    "    noisy_label_input = Input(shape=(10,))\n",
    "    \n",
    "    # feature extractor model \n",
    "    feature_model = feature_extractor()\n",
    "\n",
    "    image_features = feature_model(image_input)\n",
    "    \n",
    "    # combine the image features and noisy label input\n",
    "    combined_input = layers.concatenate([image_features, noisy_label_input])\n",
    "    # add a dense layer with ReLU activation on top of the combined input\n",
    "    combined_input = layers.Dense(128, activation='relu')(combined_input)\n",
    "    \n",
    "    # add a final dense layer with softmax activation to predict the corrected labels\n",
    "    corrected_labels = layers.Dense(10, activation='softmax')(combined_input)\n",
    "    \n",
    "    # create the Model object\n",
    "    model = Model(inputs=[image_input, noisy_label_input], outputs=corrected_labels)\n",
    "    # compile the model with the Adam optimizer, categorical crossentropy loss, and accuracy metric\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model2 = label_correction_model()\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=5243)\n",
    "clean_labels_train_cat = tf.keras.utils.to_categorical(clean_labels_train)\n",
    "noisy_labels_train_cat = tf.keras.utils.to_categorical(noisy_labels_train)\n",
    "\n",
    "for train_index, val_index in kf.split(clean_imgs_train):\n",
    "    x_train, x_val = clean_imgs_train[train_index], clean_imgs_train[val_index]\n",
    "    y_train, y_val = clean_labels_train_cat[train_index], clean_labels_train_cat[val_index]\n",
    "    noisy_y_train, noisy_y_val = noisy_labels_train_cat[train_index], noisy_labels_train_cat[val_index]\n",
    "\n",
    "    model2 = label_correction_model()\n",
    "    model2.fit(\n",
    "        [x_train, noisy_y_train], y_train,\n",
    "        validation_data=([x_val, noisy_y_val], y_val),\n",
    "        epochs=10, batch_size=32,\n",
    "        callbacks=[lr_scheduler, model_checkpoint]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c2f36a0-7286-4e14-9ef9-efb54ba4ea70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict labels for noisy images\n",
    "predicted_probabilities = model2.predict([noisy_imgs_train, noisy_labels_train_cat])\n",
    "\n",
    "# Convert probabilities to labels\n",
    "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
    "\n",
    "#threshold,>0.9 in any class\n",
    "confidence_threshold = 0.9\n",
    "high_confidence_indices = np.where(np.max(predicted_probabilities, axis=1) > confidence_threshold)[0]\n",
    "\n",
    "# Generate pseudo labels for high confidence predictions\n",
    "pseudo_labels = predicted_labels[high_confidence_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "15c4bff2-d548-436b-993b-14f23801c614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.4196 - loss: 1.6546 - val_accuracy: 0.6619 - val_loss: 0.9976 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6820 - loss: 0.9550 - val_accuracy: 0.7301 - val_loss: 0.8121 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7503 - loss: 0.7694 - val_accuracy: 0.7584 - val_loss: 0.7348 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7994 - loss: 0.6252 - val_accuracy: 0.7671 - val_loss: 0.7045 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8324 - loss: 0.5122 - val_accuracy: 0.7473 - val_loss: 0.7897 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8690 - loss: 0.4012 - val_accuracy: 0.7648 - val_loss: 0.7679 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8912 - loss: 0.3127 - val_accuracy: 0.7576 - val_loss: 0.8466 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9434 - loss: 0.1738 - val_accuracy: 0.7682 - val_loss: 0.9254 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9696 - loss: 0.1013 - val_accuracy: 0.7699 - val_loss: 1.0345 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9790 - loss: 0.0744 - val_accuracy: 0.7680 - val_loss: 1.1241 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.4109 - loss: 1.6717 - val_accuracy: 0.6573 - val_loss: 1.0220 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6669 - loss: 0.9818 - val_accuracy: 0.7207 - val_loss: 0.8343 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7348 - loss: 0.7927 - val_accuracy: 0.7604 - val_loss: 0.7111 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7918 - loss: 0.6250 - val_accuracy: 0.7648 - val_loss: 0.7262 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8289 - loss: 0.5202 - val_accuracy: 0.7696 - val_loss: 0.7297 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8669 - loss: 0.3966 - val_accuracy: 0.7673 - val_loss: 0.7461 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9142 - loss: 0.2581 - val_accuracy: 0.7730 - val_loss: 0.8377 - learning_rate: 5.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.1646 - val_accuracy: 0.7785 - val_loss: 0.9277 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9647 - loss: 0.1153 - val_accuracy: 0.7680 - val_loss: 1.0391 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9797 - loss: 0.0744 - val_accuracy: 0.7751 - val_loss: 1.0827 - learning_rate: 2.5000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.4133 - loss: 1.6697 - val_accuracy: 0.6651 - val_loss: 0.9933 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6813 - loss: 0.9417 - val_accuracy: 0.7192 - val_loss: 0.8386 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7416 - loss: 0.7789 - val_accuracy: 0.7479 - val_loss: 0.7451 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.6047 - val_accuracy: 0.7485 - val_loss: 0.7578 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8369 - loss: 0.4905 - val_accuracy: 0.7675 - val_loss: 0.7424 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8785 - loss: 0.3755 - val_accuracy: 0.7618 - val_loss: 0.8320 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9088 - loss: 0.2789 - val_accuracy: 0.7591 - val_loss: 0.8610 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9302 - loss: 0.2090 - val_accuracy: 0.7509 - val_loss: 0.9671 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9662 - loss: 0.1091 - val_accuracy: 0.7675 - val_loss: 1.0703 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9809 - loss: 0.0659 - val_accuracy: 0.7686 - val_loss: 1.1934 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.3925 - loss: 1.7003 - val_accuracy: 0.6546 - val_loss: 0.9975 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6693 - loss: 0.9796 - val_accuracy: 0.7228 - val_loss: 0.8141 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7395 - loss: 0.7852 - val_accuracy: 0.7369 - val_loss: 0.8106 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7873 - loss: 0.6480 - val_accuracy: 0.7576 - val_loss: 0.7239 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8337 - loss: 0.4994 - val_accuracy: 0.7587 - val_loss: 0.7574 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8632 - loss: 0.3977 - val_accuracy: 0.7549 - val_loss: 0.7967 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9008 - loss: 0.3069 - val_accuracy: 0.7570 - val_loss: 0.8539 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9508 - loss: 0.1632 - val_accuracy: 0.7557 - val_loss: 1.0090 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9716 - loss: 0.0986 - val_accuracy: 0.7553 - val_loss: 1.1621 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9786 - loss: 0.0748 - val_accuracy: 0.7565 - val_loss: 1.2317 - learning_rate: 5.0000e-04\n",
      "Epoch 1/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.4053 - loss: 1.6920 - val_accuracy: 0.6732 - val_loss: 0.9565 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6864 - loss: 0.9363 - val_accuracy: 0.7264 - val_loss: 0.8354 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7603 - loss: 0.7310 - val_accuracy: 0.7405 - val_loss: 0.7569 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.6086 - val_accuracy: 0.7348 - val_loss: 0.8332 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8335 - loss: 0.4942 - val_accuracy: 0.7555 - val_loss: 0.7689 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8732 - loss: 0.3793 - val_accuracy: 0.7538 - val_loss: 0.8378 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9208 - loss: 0.2404 - val_accuracy: 0.7682 - val_loss: 0.8890 - learning_rate: 5.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9507 - loss: 0.1493 - val_accuracy: 0.7638 - val_loss: 0.9612 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9701 - loss: 0.1009 - val_accuracy: 0.7560 - val_loss: 1.0811 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1316/1316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9828 - loss: 0.0608 - val_accuracy: 0.7631 - val_loss: 1.1569 - learning_rate: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, Input, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_final_model_with_lstm(input_shape=(32, 32, 3), num_classes=10):\n",
    "    # input layer\n",
    "    image_input = Input(shape=input_shape)\n",
    "    \n",
    "    # convolutional layers\n",
    "    x = layers.Conv2D(24, (3, 3), padding='same', activation='relu')(image_input)\n",
    "    x = layers.Conv2D(24, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(48, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    #  LSTM layer\n",
    "\n",
    " \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Reshape((1, -1))(x)  \n",
    "    # LSTM layer\n",
    "    x = layers.LSTM(64)(x)\n",
    "\n",
    "    # Dense layers\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "\n",
    "    model = Model(inputs=image_input, outputs=output)\n",
    "    \n",
    "  \n",
    "    model.compile(optimizer=Adam(0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "x_train_combined = np.concatenate([clean_imgs_train, noisy_imgs_train[high_confidence_indices]])\n",
    "y_train_combined = np.concatenate([clean_labels[1000:10000], pseudo_labels]) \n",
    "kf_combined = KFold(n_splits=5, shuffle=True, random_state=5243)\n",
    "\n",
    "for train_index, val_index in kf_combined.split(x_train_combined):\n",
    "\n",
    "    x_train, x_val = x_train_combined[train_index], x_train_combined[val_index]\n",
    "    y_train, y_val = y_train_combined[train_index], y_train_combined[val_index]\n",
    "\n",
    "    final_model =build_final_model_with_lstm()\n",
    "    final_model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=10, batch_size=16,\n",
    "        callbacks=[lr_scheduler, model_checkpoint] \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a107cff-0be7-451e-8e91-b95a2894077f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "final_model.save(\"model2_eva.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "89a6f363-96be-4898-b987-3dd351f39661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "\n",
    "n_test = 1000\n",
    "test_imgs = np.empty((n_test, 32, 32, 3), dtype=np.float32)\n",
    "    \n",
    "for i in range(n_test):\n",
    "    img_fn = f'../data/images/{i+1:05d}.png'\n",
    "    img = cv2.imread(img_fn)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255.0  \n",
    "    test_imgs[i] = img\n",
    "def model_II(image):\n",
    "\n",
    "\n",
    "\n",
    "    final_model = load_model(\"model2_eva.hdf5\")\n",
    "\n",
    "    predicted_probabilities = final_model.predict(image)\n",
    "    \n",
    "    model2_label= np.argmax(predicted_probabilities, axis=1)\n",
    "    return model2_label\n",
    "def model_I(image):\n",
    "\n",
    "\n",
    "\n",
    "    final_model = load_model(\"model1.hdf5\")\n",
    "\n",
    "    predicted_probabilities = final_model.predict(image)\n",
    "    \n",
    "    model1_label= np.argmax(predicted_probabilities, axis=1)\n",
    "    return model1_label\n",
    "model2_label=model_II(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "88154fac-3512-4157-ba41-32d10e393a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, 4, 1, 6, 4, 7, 0, 9, 4, 7, 7, 1, 9, 9, 9, 4, 6, 9, 4, 0,\n",
       "       6, 6, 2, 3, 3, 7, 4, 0, 8, 9, 1, 6, 2, 7, 8, 7, 8, 0, 2, 7, 4, 7,\n",
       "       1, 1, 1, 0, 4, 3, 2, 5, 7, 9, 2, 2, 5, 2, 4, 9, 1, 1, 8, 2, 1, 1,\n",
       "       4, 9, 7, 8, 0, 1, 6, 7, 2, 1, 9, 0, 9, 0, 3, 2, 4, 3, 4, 7, 4, 7,\n",
       "       9, 4, 2, 4, 8, 0, 1, 6, 1, 9, 6, 8, 8, 3, 9, 6, 6, 1, 8, 3, 2, 9,\n",
       "       8, 8, 9, 7, 5, 0, 8, 6, 9, 1, 2, 4, 9, 5, 6, 6, 1, 9, 3, 0, 6, 7,\n",
       "       3, 7, 1, 8, 1, 8, 2, 8, 9, 6, 2, 6, 4, 4, 9, 8, 5, 4, 4, 0, 7, 4,\n",
       "       6, 8, 5, 3, 7, 6, 1, 8, 7, 7, 6, 9, 1, 5, 1, 3, 8, 5, 7, 3, 3, 4,\n",
       "       1, 5, 4, 5, 2, 7, 3, 5, 1, 8, 9, 6, 9, 9, 8, 0, 8, 8, 2, 7, 6, 3,\n",
       "       5, 8, 6, 1, 9, 5, 6, 9, 1, 9, 9, 6, 6, 9, 1, 0, 9, 3, 8, 6, 2, 9,\n",
       "       0, 8, 8, 9, 6, 9, 1, 0, 6, 3, 1, 6, 6, 0, 6, 6, 1, 7, 1, 5, 8, 6,\n",
       "       4, 6, 8, 6, 8, 4, 9, 2, 1, 3, 8, 2, 4, 1, 7, 9, 3, 0, 4, 1, 1, 2,\n",
       "       0, 9, 5, 9, 4, 9, 9, 5, 7, 9, 7, 1, 0, 3, 9, 5, 8, 2, 6, 9, 8, 5,\n",
       "       6, 4, 3, 7, 8, 8, 6, 0, 4, 9, 7, 5, 1, 2, 6, 3, 6, 0, 1, 7, 9, 9,\n",
       "       0, 8, 8, 1, 1, 6, 5, 2, 9, 0, 7, 9, 7, 7, 1, 1, 5, 1, 6, 6, 8, 7,\n",
       "       1, 3, 0, 5, 3, 4, 4, 4, 5, 3, 9, 0, 4, 4, 0, 2, 2, 4, 0, 0, 4, 6,\n",
       "       8, 8, 1, 6, 9, 9, 5, 6, 9, 3, 7, 4, 9, 8, 5, 9, 6, 9, 5, 4, 4, 0,\n",
       "       5, 9, 0, 2, 4, 8, 2, 6, 7, 2, 3, 9, 7, 6, 7, 1, 3, 7, 2, 1, 7, 3,\n",
       "       1, 0, 4, 4, 7, 8, 2, 2, 1, 0, 9, 9, 9, 7, 8, 8, 7, 4, 9, 0, 8, 0,\n",
       "       8, 9, 2, 2, 7, 7, 5, 2, 5, 1, 9, 4, 8, 4, 1, 5, 4, 4, 0, 6, 9, 3,\n",
       "       7, 8, 8, 9, 9, 6, 3, 4, 8, 5, 5, 6, 6, 0, 1, 8, 8, 0, 2, 0, 8, 1,\n",
       "       5, 2, 6, 8, 9, 0, 0, 7, 7, 7, 9, 4, 2, 8, 3, 2, 5, 1, 9, 7, 9, 6,\n",
       "       4, 8, 1, 8, 6, 4, 4, 5, 7, 1, 3, 9, 5, 0, 1, 0, 7, 8, 5, 8, 0, 0,\n",
       "       9, 4, 9, 8, 5, 9, 9, 2, 7, 5, 7, 7, 8, 8, 4, 4, 6, 7, 1, 6, 6, 8,\n",
       "       4, 6, 9, 7, 9, 2, 5, 7, 9, 4, 2, 2, 6, 9, 5, 4, 7, 7, 8, 1, 5, 3,\n",
       "       6, 7, 6, 9, 8, 3, 6, 0, 2, 2, 2, 1, 8, 5, 8, 9, 8, 8, 9, 5, 4, 6,\n",
       "       4, 7, 8, 4, 1, 0, 1, 9, 9, 4, 7, 9, 9, 8, 1, 6, 6, 6, 9, 6, 8, 9,\n",
       "       9, 7, 8, 6, 0, 8, 0, 8, 3, 6, 8, 3, 1, 3, 9, 8, 8, 3, 9, 1, 1, 3,\n",
       "       7, 9, 3, 6, 9, 4, 4, 9, 5, 6, 3, 8, 8, 3, 2, 8, 4, 3, 9, 1, 7, 0,\n",
       "       5, 8, 1, 7, 6, 9, 9, 6, 3, 3, 7, 6, 0, 6, 2, 3, 7, 6, 8, 9, 0, 9,\n",
       "       7, 4, 7, 0, 1, 6, 9, 6, 9, 4, 2, 7, 9, 4, 4, 5, 1, 4, 6, 9, 6, 3,\n",
       "       2, 9, 7, 6, 7, 0, 4, 4, 9, 3, 6, 6, 0, 0, 6, 3, 0, 9, 1, 6, 6, 5,\n",
       "       8, 6, 9, 8, 5, 2, 4, 4, 5, 0, 4, 8, 8, 3, 6, 9, 6, 6, 7, 9, 2, 5,\n",
       "       3, 5, 5, 5, 3, 9, 3, 0, 5, 0, 8, 2, 6, 5, 3, 8, 2, 1, 7, 6, 7, 6,\n",
       "       0, 8, 2, 5, 0, 9, 3, 5, 9, 0, 2, 7, 7, 1, 5, 0, 4, 0, 8, 5, 9, 3,\n",
       "       6, 7, 1, 8, 0, 5, 3, 8, 3, 2, 4, 6, 0, 0, 5, 5, 0, 8, 3, 7, 2, 9,\n",
       "       6, 8, 7, 8, 2, 7, 6, 4, 2, 6, 2, 3, 6, 3, 6, 6, 0, 3, 4, 8, 8, 3,\n",
       "       5, 9, 8, 4, 6, 9, 6, 5, 0, 1, 7, 7, 8, 2, 9, 7, 2, 4, 3, 1, 1, 9,\n",
       "       6, 3, 6, 5, 1, 1, 7, 9, 7, 8, 5, 4, 1, 4, 6, 6, 6, 3, 5, 1, 4, 2,\n",
       "       3, 8, 8, 3, 0, 3, 4, 6, 8, 9, 9, 5, 8, 0, 8, 9, 6, 5, 2, 9, 2, 1,\n",
       "       8, 9, 7, 9, 3, 0, 9, 4, 8, 0, 9, 8, 8, 9, 5, 6, 4, 8, 7, 6, 9, 8,\n",
       "       8, 6, 6, 0, 0, 2, 5, 8, 2, 0, 6, 2, 6, 9, 4, 9, 5, 5, 6, 6, 5, 2,\n",
       "       6, 4, 7, 8, 2, 6, 4, 6, 3, 2, 7, 6, 9, 6, 8, 6, 1, 4, 1, 8, 7, 4,\n",
       "       1, 1, 7, 5, 9, 4, 4, 9, 7, 4, 7, 2, 1, 4, 2, 2, 9, 2, 9, 8, 4, 8,\n",
       "       7, 3, 9, 8, 7, 7, 8, 4, 2, 1, 1, 2, 1, 4, 4, 0, 3, 6, 6, 8, 3, 4,\n",
       "       2, 1, 3, 7, 7, 6, 4, 1, 2, 5], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6d1c3f7a-0cb3-4ba4-8c99-f19cf56f3410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.7088607594936709,\n",
       "  'recall': 0.5490196078431373,\n",
       "  'f1-score': 0.6187845303867404,\n",
       "  'support': 102.0},\n",
       " '1': {'precision': 0.8043478260869565,\n",
       "  'recall': 0.6607142857142857,\n",
       "  'f1-score': 0.7254901960784315,\n",
       "  'support': 112.0},\n",
       " '2': {'precision': 0.55,\n",
       "  'recall': 0.4444444444444444,\n",
       "  'f1-score': 0.4916201117318436,\n",
       "  'support': 99.0},\n",
       " '3': {'precision': 0.3815789473684211,\n",
       "  'recall': 0.31521739130434784,\n",
       "  'f1-score': 0.34523809523809523,\n",
       "  'support': 92.0},\n",
       " '4': {'precision': 0.5436893203883495,\n",
       "  'recall': 0.5656565656565656,\n",
       "  'f1-score': 0.5544554455445545,\n",
       "  'support': 99.0},\n",
       " '5': {'precision': 0.4935064935064935,\n",
       "  'recall': 0.4470588235294118,\n",
       "  'f1-score': 0.4691358024691358,\n",
       "  'support': 85.0},\n",
       " '6': {'precision': 0.5923076923076923,\n",
       "  'recall': 0.719626168224299,\n",
       "  'f1-score': 0.649789029535865,\n",
       "  'support': 107.0},\n",
       " '7': {'precision': 0.693069306930693,\n",
       "  'recall': 0.6862745098039216,\n",
       "  'f1-score': 0.6896551724137931,\n",
       "  'support': 102.0},\n",
       " '8': {'precision': 0.7073170731707317,\n",
       "  'recall': 0.8787878787878788,\n",
       "  'f1-score': 0.7837837837837839,\n",
       "  'support': 99.0},\n",
       " '9': {'precision': 0.6115107913669064,\n",
       "  'recall': 0.8252427184466019,\n",
       "  'f1-score': 0.7024793388429752,\n",
       "  'support': 103.0},\n",
       " 'accuracy': 0.616,\n",
       " 'macro avg': {'precision': 0.6086188210619914,\n",
       "  'recall': 0.6092042393754894,\n",
       "  'f1-score': 0.6030431506025218,\n",
       "  'support': 1000.0},\n",
       " 'weighted avg': {'precision': 0.6147993059530343,\n",
       "  'recall': 0.616,\n",
       "  'f1-score': 0.609393072444342,\n",
       "  'support': 1000.0}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(clean_labels[:1000]  ,model2_label,zero_division=0, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b733c88c-957c-4d70-b465-e7d716213ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "def evaluation(model, test_labels, test_imgs):\n",
    "    y_true = test_labels\n",
    "    y_pred = []\n",
    "    for image in test_imgs:\n",
    "        y_pred.append(model(image))\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e4cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "# This is the code for evaluating the prediction performance on a testset\n",
    "# You will get an error if running this cell, as you do not have the testset\n",
    "# Nonetheless, you can create your own validation set to run the evlauation\n",
    "+\n",
    "evaluation(baseline_model, test_labels, test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "de297be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "n_test = 10000\n",
    "test_imgs = np.empty((n_test, 32, 32, 3), dtype=np.float32)\n",
    "    \n",
    "for i in range(n_test):\n",
    "    img_fn = f'../data/images/{i+1:05d}.png'\n",
    "    img = cv2.imread(img_fn)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255.0  \n",
    "    test_imgs[i] = img\n",
    "def model_II(image):\n",
    "\n",
    "\n",
    "\n",
    "    final_model = load_model(\"model2.hdf5\")\n",
    "\n",
    "    predicted_probabilities = final_model.predict(image)\n",
    "    \n",
    "    model2_label= np.argmax(predicted_probabilities, axis=1)\n",
    "    return model2_label\n",
    "def model_I(image):\n",
    "\n",
    "\n",
    "\n",
    "    final_model = load_model(\"model1.hdf5\")\n",
    "\n",
    "    predicted_probabilities = final_model.predict(image)\n",
    "    \n",
    "    model1_label= np.argmax(predicted_probabilities, axis=1)\n",
    "    return model1_label\n",
    "model2_label=model_II(test_imgs)\n",
    "model1_label=model_I(test_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4aff13-f673-4c9f-b0d3-32980e3d0280",
   "metadata": {},
   "source": [
    "baseline output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "05b2984b-d6a6-44f1-ab30-859c1d8991ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_final = np.empty((10000,32,32,3))\n",
    "for i in range(10000):\n",
    "    img_fn_final = f'../data/images/{i+1:05d}.png'\n",
    "    imgs_final[i,:,:,:]=cv2.cvtColor(cv2.imread(img_fn_final),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "no_bins = 6\n",
    "bins = np.linspace(0,255,no_bins) # the range of the rgb histogram\n",
    "target_vec = np.empty(n_img)\n",
    "feature_mtx = np.empty((n_img,3*(len(bins)-1)))\n",
    "i = 0\n",
    "for i in range(n_img):\n",
    "    # The target vector consists of noisy labels\n",
    "    target_vec[i] = noisy_labels[i]\n",
    "    \n",
    "    # Use the numbers of pixels in each bin for all three channels as the features\n",
    "    feature1 = np.histogram(imgs[i][:,:,0],bins=bins)[0] \n",
    "    feature2 = np.histogram(imgs[i][:,:,1],bins=bins)[0]\n",
    "    feature3 = np.histogram(imgs[i][:,:,2],bins=bins)[0]\n",
    "    \n",
    "    # Concatenate three features\n",
    "    feature_mtx[i,] = np.concatenate((feature1, feature2, feature3), axis=None)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1178065f-d488-444c-a676-93119742bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(feature_mtx, target_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "59e9191f-80a4-41e0-a602-764994a72211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 7.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 9.0,\n",
       " 7.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 9.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 9.0,\n",
       " 0.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 9.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 9.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 9.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 8.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 2.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 9.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 9.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 9.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 9.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 9.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 9.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 9.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 7.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 9.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 9.0,\n",
       " 7.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 9.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 5.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 5.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 9.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 9.0,\n",
       " 8.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 2.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 5.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 8.0,\n",
       " 7.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 9.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 9.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 9.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 5.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 9.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 9.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 5.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 3.0,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 9.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 9.0,\n",
       " 4.0,\n",
       " 9.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 9.0,\n",
       " 0.0,\n",
       " 9.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 3.0,\n",
       " 5.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 3.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 7.0,\n",
       " 3.0,\n",
       " 9.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 5.0,\n",
       " 9.0,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 7.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 9.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 2.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 5.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 9.0,\n",
       " 9.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 7.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 5.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 5.0,\n",
       " 3.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 9.0,\n",
       " 5.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 9.0,\n",
       " 6.0,\n",
       " 9.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 3.0,\n",
       " 8.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 5.0,\n",
       " 8.0,\n",
       " 3.0,\n",
       " 9.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 3.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 0.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 7.0,\n",
       " 6.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 9.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 9.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 7.0,\n",
       " 1.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 6.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 2.0,\n",
       " 6.0,\n",
       " 1.0,\n",
       " 8.0,\n",
       " 6.0,\n",
       " 8.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 9.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 8.0,\n",
       " 4.0,\n",
       " 6.0,\n",
       " 6.0,\n",
       " 2.0,\n",
       " 9.0,\n",
       " 3.0,\n",
       " ...]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_model(image):\n",
    "    '''\n",
    "    This is the baseline predictive model that takes in the image and returns a label prediction\n",
    "    '''\n",
    "    feature1 = np.histogram(image[:,:,0],bins=bins)[0]\n",
    "    feature2 = np.histogram(image[:,:,1],bins=bins)[0]\n",
    "    feature3 = np.histogram(image[:,:,2],bins=bins)[0]\n",
    "    feature = np.concatenate((feature1, feature2, feature3), axis=None).reshape(1,-1)\n",
    "    return clf.predict(feature)\n",
    "baseline_label = []\n",
    "for i in imgs_final: \n",
    "    baseline_label.append(baseline_model(i)[0])      \n",
    "baseline_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "19c54286-f965-49aa-b833-135c8cb62fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 1, 9, 5], dtype=int64)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7730316e-dcf5-4d95-8683-58bd3a3dfa0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, ..., 1, 5, 7], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7d7c81f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'model_comparisons.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'baseline_label': baseline_label,\n",
    "    'model1_label': model1_label,\n",
    "    'model2_label': model2_label\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "predictions_df.to_csv('model_comparisons.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'model_comparisons.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bac0a7",
   "metadata": {},
   "source": [
    "The overall accuracy is $0.24$, which is better than random guess (which should have a accuracy around $0.10$). For the project, you should try to improve the performance by the following strategies:\n",
    "\n",
    "- Consider a better choice of model architectures, hyperparameters, or training scheme for the predictive model;\n",
    "- Use both `clean_noisy_trainset` and `noisy_trainset` for model training via **weakly supervised learning** methods. One possible solution is to train a \"label-correction\" model using the former, correct the labels in the latter, and train the final predictive model using the corrected dataset.\n",
    "- Apply techniques such as $k$-fold cross validation to avoid overfitting;\n",
    "- Any other reasonable strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671bd4d6-6ecc-495c-9440-e0d26bfbf814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
